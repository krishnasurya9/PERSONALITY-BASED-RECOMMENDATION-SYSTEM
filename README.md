# Personal Taste Engine

A Full-Stack AI Application that provides entertainment recommendations (Movies, Books, Music, Games) based on your personality traits.

## ğŸŒŸ Features
- **Personality Analysis**: Uses a fine-tuned BERT-LSTM model to analyze your Big Five personality traits from text responses.
- **Dynamic Recommendations**: Recommends varied genres based on your specific personality profile.
- **Multi-Domain**: Covers Movies, Books, Music, and Games.
- **Modern UI**: A sleek, dark-themed interface with interactive elements and animations.

## ğŸ“ Project Structure
```
project3/
â”œâ”€â”€ backend/            # FastAPI Backend
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py     # API Entry Point
â”‚       â”œâ”€â”€ model.py    # AI Model Definition
â”‚       â””â”€â”€ ...
â”œâ”€â”€ frontend/           # Web Interface
â”œâ”€â”€ data/               # Training Datasets (CSVs/JSONLs excluded from repo)
â”œâ”€â”€ models/             # Trained PyTorch Model (Binaries excluded from repo)
â”œâ”€â”€ training/           # Model Training Scripts
â”‚   â”œâ”€â”€ fine tunning.py # Main training script
â”‚   â””â”€â”€ evaluation.py   # Evaluation scripts
â””â”€â”€ evaluation/         # Performance Plots & Results
    â”œâ”€â”€ plots/          # Confusion Matrices, ROC Curves
    â””â”€â”€ results.txt     # Numeric metrics
```

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- API Keys for TMDB, Google Books, YouTube, and RAWG (stored in `.env`).

### 1. Backend Setup
Navigate to the backend directory:
```bash
cd backend
pip install -r requirements.txt
```

Create a `.env` file in `backend/` with your keys:
```env
TMDB_API_KEY=your_key
YOUTUBE_API_KEY=your_key
BOOKS_API_KEY=your_key
RAWG_API_KEY=your_key
```

Run the server:
```bash
python -m app.main
```
The API will run at `http://127.0.0.1:8000`.

### 2. Frontend Setup
You can simply open `frontend/index.html` in your browser.
For the best experience, run a local server:
```bash
cd frontend
python -m http.server 8080
```
Open `http://127.0.0.1:8080`.

## ğŸ§  Model Training (Required)

**Note:** The trained model files (`.pth`) and large datasets are **not included** in this repository to keep it lightweight. You must train the model locally to use the personality analysis feature.

### How to Train the Model
1.  **Prepare Data**: Place your Big Five dataset (JSONL format) in `data/processed data/big_five_prompts.jsonl`.
2.  **Run Training Script**:
    ```bash
    cd training
    python "fine tunning.py"
    ```
3.  **Output**:
    - The script will train the BERT-LSTM model on your GPU (if available) or CPU.
    - The best model will be saved to `models/best_bert_lstm.pth`.
    - Logs are saved to `status.txt`.

## ğŸ“Š Evaluation Results

We have included comprehensive evaluation metrics for the model in the `evaluation/` directory.

- **Plots**: View confusion matrices and ROC curves in `evaluation/plots/`.
- **Metrics**: Detailed accuracy, precision, recall, and F1-scores are available in `evaluation/results.txt`.

### Model Architecture
The system uses a **BERT-LSTM** architecture:
1.  **BERT (Base Uncased)**: Extracts contextual embeddings from user responses.
2.  **Bi-Directional LSTM**: Captures sequential dependencies in the text.
3.  **Fully Connected Layer**: Maps the output to 5 personality trait scores.

## ğŸ“ Credits
Developed as part of Project 3.
